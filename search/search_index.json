{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This is a blog. It may contain interesting things but most likely not.</p>"},{"location":"Collatz/Matrix%20Approach/","title":"Matrix Approach","text":"<p>The Collatz conjecture is a well-known problem. I won't make the claim to make any new findings here. However, I have never seen the problem be approached like this (but well, I didn't search very much). So this could be of interest to you.</p> <p>Let the Collatz process be defined as</p> \\[ \\left\\{     \\begin{array}{ll}       \\frac{3x_n+1}{2}=x_n+1\\text{ if }x_n\\text{ is odd}\\\\       \\frac{x_n}{2}=x_n+1\\text{ if }x_n\\text{ is even}\\\\     \\end{array} \\right. \\] <p>Let</p> \\[ \\displaylines{ u_n = \\left\\{     \\begin{array}{ll}       3\\text{ if }x_n\\text{ is odd}\\\\       1\\text{ if }x_n\\text{ is even}\\\\     \\end{array} \\right.\\\\ v_n = \\left\\{     \\begin{array}{ll}       1\\text{ if }x_n\\text{ is odd}\\\\       0\\text{ if }x_n\\text{ is even}\\\\     \\end{array} \\right. } \\] <p>we then have</p> \\[ 2x_{n+1}-u_nx_n=v_n. \\] <p>This is a linear equation. We can then define the two vectors</p> \\[ \\displaylines{ X = \\begin{pmatrix}     x_{0} \\\\     x_{1} \\\\     \\vdots \\\\     x_{n} \\end{pmatrix}\\\\ V = \\begin{pmatrix}     v_{0} \\\\     v_{1} \\\\     \\vdots \\\\     v_{n} \\end{pmatrix} } \\] <p>Let also define the matrix</p> \\[ U = \\begin{pmatrix}     -u_0&amp; 2 &amp; 0&amp;0 &amp; \\cdots &amp;0  \\\\     0&amp; -u_1 &amp; 2&amp; 0&amp;\\cdots&amp;0 \\\\     0&amp;0&amp;-u_2&amp;2&amp;\\cdots&amp;0\\\\     0&amp;0&amp;0&amp;-u_3&amp;\\cdots&amp;0\\\\     \\vdots &amp;\\vdots&amp; \\vdots&amp; \\vdots&amp; \\ddots&amp; \\vdots \\\\     2 &amp; 0 &amp;0  &amp;0&amp;\\cdots&amp;-u_n \\end{pmatrix}\\\\ \\] <p>Note that all elements of the vectors should be positive integers to represent a valid Collatz sequence.  We have a cycle in the Collatz sequence if</p> \\[ UX=V \\] <p>To solve this, we can transform U in the following way:</p> Transformation \\(l_n\\) \\(l_n\\leftarrow u_0l_n+2l_0\\) \\(l_n = \\begin{pmatrix} 0 &amp;    4&amp;0&amp;0&amp;\\cdots&amp;-u_0u_n\\end{pmatrix}\\) \\(l_n\\leftarrow u_1l_n+4l_1\\) \\(l_n = \\begin{pmatrix} 0 &amp;    0&amp;8&amp;0&amp;\\cdots&amp;-u_0u_1u_n\\end{pmatrix}\\) \\(\\vdots\\) \\(\\vdots\\) \\(l_n\\leftarrow u_{n-1}l_n+2^nl_{n-1}\\) \\(l_n = \\begin{pmatrix} 0 &amp;    0&amp;0&amp;0&amp;\\cdots&amp;2^{n+1}-\\prod_{i=0}^n u_i\\end{pmatrix}\\) <p>To keep equality, we apply the same transformation to \\(V\\)</p> Transformation \\(v_n\\) \\(v_n\\leftarrow u_0v_n+2v_0\\) \\(v_n = u_0v_n+2v_0\\) \\(v_n\\leftarrow u_1v_n+4v_1\\) \\(v_n = u_1(u_0v_n+2v_0)+4v_1\\) \\(\\vdots\\) \\(\\vdots\\) \\(v_n\\leftarrow u_{n-1}v_n+2^nv_{n-1}\\) \\(v_n = v_0\\prod_{i=0}^{n-1}u_i+\\sum_{i=0}^{n-1}(2^{i+1}v_i\\prod_{j=i+1}^{n-1}u_j)\\) <p>The equality thus gives</p> \\[ \\left(2^{n+1}-\\prod_{i=0}^nu_i\\right)\\underbrace{x_n}_{&gt;0}=\\underbrace{v_n\\prod_{i=0}^{n-1}u_i}_{&gt;0}+\\underbrace{\\sum_{i=0}^{n-1}\\left(2^{i+1}v_i\\prod_{j=i+1}^{n-1}u_j\\right)}_{&gt;0} \\] <p>For a valid cycle, we thus have</p> \\[ 2^{n+1}&gt;\\prod_{i=0}^{n}u_i=3^k \\] <p>with \\(k\\), the number of odd numbers in the cycle. This gives us an upperbound on the number of odd numbers in a cycle:</p> \\[ \\frac{n+1}{\\log_2(3)}&gt;k. \\] <p>I want to point out this is in now way new but I didn't see this way to get it, even if equivalent methods have probably been used.</p> <p>If one could prove that</p> \\[ \\frac{v_n\\prod_{i=0}^{n-1}u_i+\\sum_{i=0}^{n-1}2^{i+1}v_i\\prod_{j=i+1}^{n-1}u_i}{2^{n+1}-3^k} \\] <p>is never an positive integer other than 1 and 2, he would have proven that there is no other cycles. It would still not be sufficient to prove the Collatz conjecture as this does not eliminates the possibility that a sequence infinitely increases.</p>"},{"location":"Complex%20Chebychev/Introduction/","title":"Introduction","text":"<p>An interesting way to study complex function is to consider them as a \\(R\\rightarrow R^2\\) function. Let \\(f\\), a function defined over the complex numbers. We can then look at</p> \\[ (t, \\Re{[f(t)]}, \\Im{[f(t)]}) \\] <p>as a 3D plot. Doing so, some operation appear as well-known geometric operations over a whole function. For example, exponentiation leads to a rotation of the points and moves them away(closer) from the origin if they have a modulus bigger(smaller) than one. When one notices this, he could search for a function on which only the rotation is applied. This means a function which always has modulus 1.</p> <p>In this case, the function looks like a coil and exponentiation makes the coil spin faster or slower.</p> <p>The first solution which should come to mind should be</p> \\[ g(t)=e^{it} \\] <p>with i, the imaginary number. One can see that this has modulus one. When exponentating, we will simply have</p> \\[ g(t)^n=g(tn). \\] <p>This is an interesting but well-known function and I don't think I could say much about it that hasn't been heard a thousand time.</p> <p>Let's take now take another function which fullfills the modulus one condition: </p> \\[ f(t,n)=\\left(t+i\\sqrt{1-t^2}\\right)^n. \\] <p>Let's look at the values of the function for the first \\(n\\)'s.</p> n f(t,n) 0 \\(1\\) 1 \\(t+i\\sqrt{1-t^2}\\) 2 \\(2t^2-1+2ti\\sqrt{1-t^2}\\) 3 \\(4t^3-3t+(4t^2-1)i\\sqrt{1-t^2}\\) 4 \\(8t^4-8t^2+1+(8t^3-4t)i\\sqrt{1-t^2}\\) <p>Now, it should be obvious that for all integer \\(n\\)'s, the function takes the form </p> \\[ f(t,n)=T_n(t)+U_{n-1}(t)i\\sqrt{1-t^2} \\] <p>with \\(T_n(t)\\) and \\(U_n(t)\\), polynomials in \\(t\\). Some of you will have directly recognised the Chebyshevs polynomyals (maybe hinted by my less than subtel choice of notation when descibing the form). If it wasn't obious to you, inputing the coeficients in the OEIS could have led you to this conclusion (as it had for me when I didn't know about Chebyshevs polynomyals).</p> <p>We can prove that this is actually true. To do so let's take the change of variables \\(t=\\cos u\\). Then we have</p> \\[ f(t,n)=\\left(\\cos u+i\\sqrt{1-\\cos^2u}\\right)^n=\\left(\\cos u+i\\sin u\\right)^n= g(u)^n=g(un) \\] <p>Undoing the change of variable leads to </p> \\[ \\displaylines{f(t,n)=g(n\\arccos t)=\\cos(n\\arccos t)+i\\frac{\\sin(n\\arccos t)}{\\sin(\\arccos t)}\\sin(\\arccos t)\\\\ =T_n(t)+iU_{n-1}(t)\\sqrt{1-t^2}} \\] <p>where \\(T_n\\) is the Chebyshev polynomial of the first kind and \\(U_n\\), the Chebyshev polynomial of the second kind.</p>"},{"location":"Complex%20Chebychev/Properties/","title":"Properties","text":"<p>Let</p> \\[ P_n=(t+i\\sqrt{1-t^2})^n=T_n+U_{n-1}i\\sqrt{1-t^2}. \\] <ul> <li>\\(P_{n+2}=2tP_{n+1}-P_n\\)</li> </ul> \\[ \\displaylines{ \\left(t+i\\sqrt{1-t^2}\\right)^{n+2}=2t\\left(t+i\\sqrt{1-t^2}\\right)^{n+1}-\\left(t+i\\sqrt{1-t^2}\\right)^{n}\\\\ \\left(t+i\\sqrt{1-t^2}\\right)^{2}=2t\\left(t+i\\sqrt{1-t^2}\\right)-1\\\\ t^2-1+t^2+2ti\\sqrt{1-t^2}=2t^2-1+2ti\\sqrt{1-t^2} } \\] <ul> <li>\\(n^2P_n-tP_n'+(1-t^2)P_n''=0\\)</li> </ul> <p>Some well-known hypothesis: </p> \\[ (1) n^2T_n-tP_n'+\\left(1-t^2\\right)T_n''=0 \\] \\[ (2) \\left(1-t^2\\right)U_{n-1}''-3tU_{n-1}'+\\left(n^2-1\\right)U_{n-1}=0 \\] <p>Now the proof:</p> \\[ \\displaylines{ n^2P_n-tP_n'+\\left(1-t^2\\right)P_n''\\\\ =n^2\\left(T_n+U_{n-1}i\\sqrt{1-t^2}\\right)-t\\left(T_n'+U_{n-1}'\\sqrt{1-t^2}i-\\frac{tU_{n-1}}{\\sqrt{1-t^2}}i\\right)\\\\ -\\left(t^2-1\\right)\\left(T_n''+U_{n-1}''i\\sqrt{1-t^2}-\\frac{2tU_{n-1}'}{\\sqrt{1-t^2}}-\\frac{U_{n-1}}{\\sqrt{(1-t^2)^3}}\\right)\\\\ =\\overbrace{\\left(n^2T_n-tT_n'+\\left(1-t^2\\right)T_n''\\right)}^{0\\text{ by }(1)}+U_{n-1}i\\left(n^2\\sqrt{1-t^2}+\\frac{t^2}{\\sqrt{1-t^2}}+\\frac{t^2-1}{\\sqrt{(1--t^2)^3}}\\right)\\\\ -U_{n-1}'i\\left(t\\sqrt{1-t^2}-\\frac{2t}{\\sqrt{1-t^2}}\\left(t^2-1\\right)\\right)-U_{n-1}''i\\sqrt{1-t^2}\\left(t^2-1\\right)\\\\ =\\frac{i}{\\sqrt{1-t^2}}\\left(\\left(n^2\\left(1-t^2\\right)+t^2-1\\right)U_{n-1}-\\left(t\\left(1-t^2\\right)+2t\\left(1-t^2\\right)\\right)U_{n-1}'+(1-t^2)^2U_{n-1}''\\right)\\\\ =i\\sqrt{1-t^2}\\left(\\left(n^2-1\\right)U_{n-1}U_{n-1}-3tU_{n-1}'+\\left(1-t^2\\right)U_{n-1}''\\right)\\\\ =0 \\text{ by (2)} } \\] <p>Those properties are shared with \\(T_n\\). The only thing that differentiates them is the initial conditions.</p>"},{"location":"Composition/Infinite%20series/1.Basic%20Introduction/","title":"1.Basic Introduction","text":"<p>Let</p> \\[ p(x)=\\sum_{i=0}^{\\infty}C_ix^i \\] <p>with \\(C_i\\in\\mathbb{R}, \\forall i \\in \\mathbb{N}\\). Let</p> \\[ p_j(x)=\\sum_{i=1}^\\infty C_{i,j}x^i, \\] <p>the \\(j\\)th composition of \\(p\\). We know that \\(p_j\\) exists because functions stay analytic under composition. Even if the original function did not converge, \\(p_j\\) still has a meaning as a formal serie. Some trivial properties: + \\(p_0(x)=x\\) + \\(p_1(x)=p(x)\\) The case with \\(C_0\\ne 0\\) is complicated as all coeficient have an impact on all coeficients. We will thus focus on the case \\(C_0=0\\) </p>"},{"location":"Composition/Infinite%20series/2.C0%3D0/","title":"2.C0=0","text":"<p>From the Basic Introduction, we thus have</p> \\[ p(x)=\\sum_{i=1}^{\\infty}C_ix^i \\] <p>and</p> \\[ p_j(x)=\\sum_{i=1}^{\\infty}C_{i,j}x^i \\] <p>as composition won't add a constant element. Applying composition, we have</p> \\[ p_{j+k}(x)=p_k(p_j(x))=\\sum_n C_{n,k}\\left(\\sum_i C_{i,j} x^i\\right)^n=\\sum_n\\sum_i C_{n,k}\\hat B_{i,n}(C_{r,j})x^i \\] <p>With \\(\\hat B(n,k)\\), the Ordinary Bell polynomial. \\(C_{r,j}= C_{r,j}|_{r=1}^\\infty\\), an ordered list as input to the polynomial. This leads us to the following defining equation:</p> \\[ C_{n,j+k}=\\sum_i C_{i,j} \\hat B_{n,i}(C_{r,k})=\\sum_i C_{i,k} \\hat B_{n,i}(C_{r,j}) \\] <p>Taking \\(k=1\\) and the second equality, one can get</p> \\[ C_{N,j}=\\frac{1}{C_2(N-2)}\\sum_{i=1}^{N-2}\\left(C_2C_{i+1,j}C_{N-i,j}+C_{i+2}\\hat B_{N+1,i+2}(C_{r,j})-C_{i+1,j}\\hat B_{N+1,i+1}(C_r)\\right) \\] <p>This is a way to compute them. A way that I found more useful was to take k=1 and The first equality.</p> \\[ C_{n,j+1}=\\sum_i C_{i,j} \\hat B_{n,i}(C) \\] <p>The case \\(C_1=1\\) is especially nice given \\(C\\) 's become polynomial in \\(j\\). This case will thus be studied in its own page that you can go to now if this is the case that interests you.</p> <p>Staying in the case \\(C_1\\ne1\\), here is some examples of \\(C\\)'s:</p> \\(i\\) \\(C_{i,j}\\) 1 \\(C_1^j\\) 2 \\(C_2\\frac{C_1^{2j}-C_1^j}{C_1^2-C_1}\\) 3 \\(\\frac{(C_1-1)C_1C_3+2C_2^2}{C_1^2(C_1-1)^2(C_1+1)}C_1^{3j}-\\frac{2C_2^2}{(C_1^2-C_1)^2}C_1^{2j}+\\frac{(1-C_1)C_3+2C_2^2}{(C_1-1)^2C_1(C_1+1)}C_1^j\\) <p>From those, we can guess the model</p> \\[ C_{i,j}=\\sum_{k=1}^i C_1^{kj}V_{i,k}(C_r|_{r=1}^i) \\] <p>Injecting it, we get</p> \\[ \\sum_k^iC_{1}^{kj+k}V_{i,k} = \\sum_{k=1}^i\\sum_{l=k}^i \\hat B_{i,l}C_1^{kj}V_{l,k} \\] <p>which is equivalent to</p> \\[ \\sum_{k=1}^iC_1^{kj}\\left(C_1^kV_{i,k}-\\sum_{l=k}^i \\hat B_{i,l} V_{l,k}\\right)=0 \\] <p>As this must be true for all \\(C_1\\), we must have</p> \\[ C_1^kV_{i,k}=\\sum_{l=k}^i \\hat B_{i,l}V_{l,k} \\] <p>Assuming</p> \\[ \\sum_{k=1}^{i}V_{i,k}=0, \\] <p>we have the following method of computation:</p> \\[ \\left\\{     \\begin{array}{ll}       V_{1,1}=1\\\\       (C_1^k-C_1^i)V_{i,k}=\\sum_{l=k}^{i-1}\\hat B_{i,l}V_{l,k}\\\\       V_{i,i} = -\\sum_{k=1}^{i-1}V_{i,k}     \\end{array} \\right. \\] <p>The third equations gives us the initial condition of the second one. The first gives the initial condition of the system. One can see that each \\(V_i,k\\) will introduce a new factor \\((C_1^k-C_1^i)^{-1}\\) so we have</p> \\[ V_{i,k}\\xrightarrow{\\prod_{l=k+1}^i(C_1^k-C_1^l)}V_{k,k}\\xrightarrow{\\prod_{l=1}^{k-1}(C_1^l-C_1^k)}V_{1,1}=1 \\] <p>We thus can model \\(V\\) as</p> \\[ V_{i,k}=\\frac{U_{i,k}}{\\prod_{l=1\\ne k}^i(C_1^k-C_1^l)} \\] <p>The second equation then becomes</p> \\[ U_{i,k}=\\sum_{l=k}^{i-1}\\hat B_{i,l} U_{l,k}\\prod_{h=l+1}^{i-1}(C_1^k-C_1^h) \\] <p>\\(U\\) has the advantage of being a \"simple\" polynomial and should thus be easier to then model and solve.</p> \\(U_{a,b}\\) b=1 2 3 a=1 \\(1\\) 2 \\(C_2\\) \\(C_2\\) 3 \\(2C_1C_2^2+C_1(1-C_1)C_3\\) \\(2C_1C_2^2\\) \\(2C_1C_2^2+C_1^2(C_1-1)C_3\\)"},{"location":"Composition/Infinite%20series/3.C0%3D0%20C1%3D1/","title":"3.C0=0 C1=1","text":"<p>Continuing from the equation</p> \\[ C_{i,j+1}=\\sum_k C_{k,j} \\hat B_{i,k}(C) \\] \\[ C_{i,j+1}-C_{1,j}C_{i,j}=\\sum_{k=1}^{i-1}C_{k,j}\\hat B_{i,k} \\] <p>Taking \\(C_1=1\\), it becomes  </p> \\[ C_{i,j+1}-C_{i,j}=\\sum_{k=1}^{i-1}C_{k,j}\\hat B_{i,k} \\] <p>We can list some \\(C_{i,j}\\):</p> \\(i\\) \\(C_{i,j}\\) 1 1 2 \\(C_2j\\) 3 \\(C_2^2j^2+(C_3-C_2^2)j\\) <p>As we can see, they are polynomials. We can thus guess the model</p> \\[ C_{i,j}=\\sum_{k=0}^{i-1}A_{i,k}j^k \\] <p>Trivial properties:</p> <ul> <li> <p>\\(A_{1,0}=1\\)</p> </li> <li> <p>\\(\\sum_{k=0}^{i-1}A_{i,k}=C_i\\)</p> </li> </ul> <p>We also have</p> \\[ C_{i,j+1}=\\sum_{k=0}^{i-1}A_{i,k}(j+1)^k=\\sum_{k=0}^\\infty j^k\\sum_{n=0}^{i-1} \\begin{pmatrix}n\\\\k\\end{pmatrix}A_{i,n}. \\] <p>Injecting it, we now have</p> \\[ \\sum_{k=0}^\\infty j^k\\sum_{n=0}^{i-1} \\begin{pmatrix}n\\\\k\\end{pmatrix}A_{i,n}-\\sum_{k=0}^{i-1}A_{i,k}j^k=\\sum_{k=1}^{i-1}\\sum_{n=0}^{k-1}A_{k,n}j^n\\hat B_{i,k} \\] \\[ \\sum_{n=0}^{i-1}\\begin{pmatrix}n\\\\k\\end{pmatrix}A_{i,n}-A_i,k=\\sum_{n=0} ^{i-1}A_{n,k}\\hat B_{i,n} \\] \\[ \\sum_{n=k+1}^{i-1}\\begin{pmatrix}n\\\\k\\end{pmatrix}A_{i,n}=\\sum_{n=k+1} ^{i-1}A_{n,k}\\hat B_{i,n} \\] <p>Let \\(n\\) such that \\(k+1=i-N\\)</p> \\[ \\sum_{n=i-N}^{i-1}\\begin{pmatrix}n\\\\i-N-1\\end{pmatrix}A_{i,n}=\\sum_{n=i-N} ^{i-1}A_{n,i-N-1}\\hat B_{i,n} \\] \\[ (i-N)A_{i,i-N}-(i-1)C_2A_{i-1,j-1-N}=\\sum_{n=0}^{N-2}A_{n+i-N,i-N-1}\\hat B_{i,n+i-N}-\\begin{pmatrix}n+i-N+1\\\\i-N-1\\end{pmatrix}A_{i,n+i-N+1} \\] <p>We can do a change of variable such that</p> \\[ A_{i,i-N}=\\frac{(i-1)!}{(i-N)!}C_2^iV_N(i) \\] <p>Injecting it in, leads, after some computation, to</p> \\[ V_N(i)-V_N(i-1)=\\sum_{n=0}^{N-2}\\hat B_{i,n+i-N}\\frac{(n+i-N-1)!}{(i-1)!}C_2^{n-N}V_{n+1}(n+i-N)-\\frac{V_{N-n-1}(i)}{(n+2)!} \\] \\[ V_N(n)=\\sum_{i=N+1}^n\\sum_{k=0}^{N-2}\\hat B_{i,k+i-N}\\frac{(k+i-N-1)!}{(i-1)!}C_2^{k-N}V_{k+1}(k+i-N)-\\frac{V_{k+1}(i)}{(N-k)!} \\] \\[ V_1(n)=\\frac{1}{C_2} \\] \\[ V_2(n)=C_2^{-3}(C_3-C_2^2)(H_n-1) \\] <p>with \\(H_n = \\sum_{i=1}^n \\frac 1i\\), the harmonic numbers. \\(V_3(n)\\) is already quite complicated and long to be shown here. Let \\(Q_N(n)=V_N(n)C_2^{N+1}\\),</p> \\[ Q_N(n)=\\sum_{i=N+1}^n\\sum_{k=0}^{N-2}\\hat B_{i,k+i-N}\\frac{(k+i-N-1)!}{(i-1)!}C_2^{-1}Q_{k+1}(k+i-N)-\\frac{C_2^{N-k-1}}{(N-k)!}Q_{k+1}(i) \\] <p>Now let </p> \\[ Q_N(n)=\\sum_{\\sum_i(i-1)j_i}U(j_i,n)\\prod_{i\\ge2}C_i^{j_i} \\] <p>Injecting it gives</p> \\[ \\displaylines{ \\sum_{\\sum_{i-1}j_i=N}U(j_r,n)C_2\\prod_{i\\ge 2}C_i^{j_i}=\\\\ \\sum_{i=N+1}^n\\sum_{k=0}^{N-2}\\left(\\sum_{\\begin{matrix}\\sum(j-1)a_j=N-k\\\\\\sum(j-1)b_j=k+1\\end{matrix}}\\frac{(k+i-N-1)!(k+i-N)!}{(i-1)!\\prod_{r=1}^{N-k+1}a_r!}U(b_i,k+i-N)\\prod_{r\\ge2}C_{r,a_r+b_r}\\\\ -\\sum_{\\sum(j-1)d_j=k+1}\\frac{U(d_r,i)}{(N-k)!}C_2^{N-k}\\prod_{r\\ge2}C_r^{d_r} \\right) } \\] <p>Identifying terms, we get</p> \\[ U(j_i,n)=\\sum_{m=N+1}^n\\sum_{k=0}^{N-2}\\left(-\\frac{U(\\{j_2+1+k-N;j_3;j_4;\\ldots\\},m)}{(N-k)!}+\\sum_{\\begin{matrix}\\sum(i-1)a_1=N-k\\\\\\sum(i-1)b_i=k+1\\\\\\left\\{     \\begin{array}{ll}       a_i+b_i=j_i, \\forall i&gt;2\\\\       a_2+b_2=j_2+1     \\end{array} \\right.\\end{matrix}} \\left(\\frac{(k+m-N)!(k+m-N-1)!}{(m-1)!(m+k-N-\\sum_{r\\ge2}a_r)!}\\frac{U(b_r,k+m-N)}{\\prod_{r\\ge2}a_r!}\\right)\\right) \\] <p>To simplify formulas, let shift \\(j\\)'s by 1 such that \\(j_2\\) is now noted as \\(j_1\\). The fomula then becomes</p> \\[ U(j_i,n)=\\sum_{m=N+1}^n\\sum_{k=0}^{N-2}\\left(-\\frac{U(\\{j_1+1+k-N;j_2;\\ldots\\},m)}{(N-k)!}+\\sum_{\\begin{matrix}\\sum ib_i=k+1\\\\a_i+b_i=j_i,\\forall i:1&lt;i&lt;N\\\\a_N=j_N\\\\a_1+b_1=j_1+1\\\\a_1\\ge0,\\forall i\\\\b_i\\ge0, \\forall i&gt;1\\end{matrix}} \\left(\\frac{(k+m-N)!(k+m-N-1)!}{(m-1)!(m+k-N-\\sum a_r)!}\\frac{U(b_r,k+m-N)}{\\prod a_r!}\\right)\\right) \\] <p>Some properties: Let \\(J(N)=\\{j_i=1 \\text{ if } i=N;j_i=0 \\text{ else}\\}\\), we have</p> \\[ U(J(N),n)=\\frac{1}{N-2}\\left(\\frac{1}{(N-1)!}-\\frac{(n-N+1)!}{(n-1)!}\\right) \\] \\[ U(\\{N\\},n)=\\sum_{m=N+1}^n\\sum_{k=0}^{N-2}\\frac 1{(N-k)!}\\left(\\frac{(k+m-N)!(k+m-N-1)!}{(m-1)!(m+2k-2N)!}U(\\{k+1\\},k+m-N)-U(\\{k+1\\},m)\\right) \\] \\[ U(\\{2-N;N-1\\},n)\\sum_{m=2N-2}^{n-1}\\frac{U(\\{3-N;N-2\\},m-1)}{m} \\] <p>From this last functions, we will define</p> \\[ F_N(n)=\\sum_{i=2N-2}^{n-1}\\frac{F_{N-1}(i-1)}{i} \\] <p>with initial condition</p> \\[ F_1(n)=1 \\] \\(J\\) \\(U(J,n)\\) {0;1} \\(F_2(n)\\) {2} \\(-F_2(n)\\) {-1;2} \\(F_3(n)\\) {3} \\(F_3(n)-\\frac 32 \\frac 1{n-1}+\\frac 34\\) {1,1} \\(\\frac 52 \\frac 1{n-1} -\\frac 54 -2 F_3(n)\\) {4} \\(\\frac{29}{72}-\\frac{7}{12}\\frac 1{n-2}-\\frac{25}{12}\\frac{1}{n-1}+\\frac 32 \\left(\\frac 1{n-1}-\\frac 12\\right) F_2(n-2)-F_4(n)\\) {1,0,1} \\(\\frac 16 -\\frac 2{n-1} +\\frac 1{n-2}+F_2(n-2)\\left(\\frac 1{n-1}- \\frac 12\\right)\\) {-1;1;1} \\(-\\frac{5}{12}+\\frac 12 \\left(\\frac{1}{n+1}+\\frac{1}{n+2}\\right)+F_2(n-2)\\left(\\frac12 -\\frac 1{n-1}\\right)\\) {2;1} \\(3F_4(n)+F_2(n-2)4\\left(\\frac 12 -\\frac{1}{n-1}\\right)+\\frac 72 \\frac{1}{n-2}+\\frac 12 \\frac{1}{n-1}-\\frac{83}{72}\\) {0;2} \\(\\frac{11}{12}-\\frac 2{n-1}-\\frac 12\\frac{1}{n-2}+\\frac 52 \\left(\\frac 1{n-1}-\\frac 12\\right)F_2(n-2)-3F_4(n)\\) <p>We can guess the form as</p> \\[ U({j_r},n)=\\sum_{l=0}^{N-1}K_l(\\{j_r\\},n)F_{N-l}(n-l) \\] <p>Through some shady techniques, we can find</p> \\[ K_0(j_1,j_2)=(-1)^{j_1+j_2+1}\\begin{pmatrix}j_1+2j_2-1\\\\j_2\\end{pmatrix} \\] \\[ K_1(j_1,j_2)=0 \\] \\[ K_2(j_1,j_2)=\\left(\\frac 12 -\\frac 1{n-1}\\right)(-1)^{j_1+j_2}\\left(\\begin{pmatrix}j_1+2j_2-3\\\\j_2\\end{pmatrix}-\\frac 52 \\begin{pmatrix}j_1+2j_2-2\\\\j_2\\end{pmatrix}\\right) \\] <p>This is actually only true if \\(j_i=0 \\forall i&gt;2\\) as all of those case, create \"parralel\" solutions, which should respect similar recurence equations but with different initial conditions.</p> <p>The form should be injected in the equation to find general solutions but the computations is very complicated and I was not able to get through with it at the moment.</p>"},{"location":"Composition/Rational/General%20Case/","title":"General Case","text":"<p>It is known that the superfunction of any rational linear function can be found. As I computed it by myself before finding it elsewhere, I will showcase my method here. It does not contain any big novelty but it showcases common methods to find superfunctions by hand.</p> <p>Let</p> \\[ p(x)=\\frac{ax+b}{x+c}. \\] <p>This describes all ratios of linear functions, while ignoring linear functions, which are simpler to treat. Let's define the \\(j\\)th composition of this function as</p> \\[ p_j(x)=\\frac{a_jx+b_j}{k_jx+c_j} \\] <p>This form of function can be guessed from doing some composition. We could get rid of \\(k_j\\) but it would complicate the computation. We know that</p> \\[ p_{j+1}(x)=p(p_j(x))=\\frac{a_jax+b_jx+a_jb+b_jc}{k_jax+c_jx+bk_j+cc_j} \\] <p>Meaning that</p> \\[ \\left\\{     \\begin{array}{ll}       a_{j+1}=a_ja+b_j\\\\       b_{j+1}=a_jb+b_jc\\\\       c_{j+1}=bk_j+cc_j\\\\       k_{j+1}=k_ja+c_j     \\end{array} \\right. \\] <p>Which is equivalent to two systems of equations:</p> \\[ \\begin{pmatrix}a_{j+1}\\\\b_{j+1}\\end{pmatrix} =\\begin{pmatrix}a&amp;1\\\\b&amp;c\\end{pmatrix} \\begin{pmatrix}a_{j}\\\\b_{j}\\end{pmatrix} \\] \\[ \\begin{pmatrix}c_{j+1}\\\\k_{j+1}\\end{pmatrix} =\\begin{pmatrix}c&amp;b\\\\1&amp;a\\end{pmatrix} \\begin{pmatrix}c_{j}\\\\k_{j}\\end{pmatrix} \\] <p>with initial conditions</p> \\[ \\begin{pmatrix}c_{0}\\\\k_{0}\\end{pmatrix}= \\begin{pmatrix}a_{0}\\\\b_{0}\\end{pmatrix}= \\begin{pmatrix}1\\\\0\\end{pmatrix} \\] <p>as \\(p_0(x)=x\\), the identity function. We now want to find</p> \\[ M_1^n=\\begin{pmatrix}a&amp;1\\\\b&amp;c\\end{pmatrix}^n \\] \\[ M_2^n=\\begin{pmatrix}c&amp;b\\\\1&amp;a\\end{pmatrix}^n \\] <p>by diagonalisation, this is equivalent to</p> \\[ M_{1/2}^n=S_{1/2}J_{1/2}^nS_{1/2}^{-1} \\] <p>with \\(J_{1/2}\\) containing the eigenvalues of \\(M_{1/2}\\) and \\(S_{1/2}\\) containing its eigenvectors. We are in fact only interested to the first column of \\(M_{1/2}^n\\) as it will be multiplied by \\(\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\).</p> <p>The result is</p> \\[ \\left\\{     \\begin{array}{ll}       a_{j}=\\frac{c-a+\\sqrt{\\rho}}{2\\sqrt{\\rho}}\\left(\\frac{a+c-\\sqrt{\\rho}}{2}\\right)^j+\\frac{a-c+\\sqrt{\\rho}}{2\\sqrt{\\rho}}\\left(\\frac{a+c+\\sqrt{\\rho}}{2}\\right)^j\\\\       b_{j}=\\frac{b}{\\sqrt{\\rho}}\\left(\\left(\\frac{a+c+\\sqrt{\\rho}}{2}\\right)^j-\\left(\\frac{a+c-\\sqrt{\\rho}}{2}\\right)^j\\right)\\\\       c_{j}=\\frac{a-c+\\sqrt{\\rho}}{2\\sqrt{\\rho}}\\left(\\frac{a+c-\\sqrt{\\rho}}{2}\\right)^j+\\frac{c-a+\\sqrt{\\rho}}{2\\sqrt{\\rho}}\\left(\\frac{a+c+\\sqrt{\\rho}}{2}\\right)^j\\\\       k_{j}=\\frac{1}{\\sqrt{\\rho}}\\left(\\left(\\frac{a+c+\\sqrt{\\rho}}{2}\\right)^j-\\left(\\frac{a+c-\\sqrt{\\rho}}{2}\\right)^j\\right)\\\\     \\end{array} \\right. \\] <p>with</p> \\[ \\rho=(a-c)^2+4b \\] <p>Let now</p> \\[ p_j(x)=\\frac{A_jx+B_j}{x+C_j} \\] <p>which leads to</p> \\[ \\left\\{     \\begin{array}{ll}       A_j=\\frac{a_j}{k_j}=\\frac{(c-a+\\sqrt{\\rho})(a+c-\\sqrt{\\rho})^j+(a-c+\\sqrt{\\rho})(a+c+\\sqrt{\\rho})^j}{2((a+c+\\sqrt{\\rho})^j-(a+c-\\sqrt{\\rho})^j)}\\\\       B_j=\\frac{b_j}{k_j}=b\\\\       C_j=\\frac{c_j}{k_j}=\\frac{(a-c+\\sqrt{\\rho})(a+c-\\sqrt{\\rho})^j+(c-a+\\sqrt{\\rho})(a+c+\\sqrt{\\rho})^j}{2((a+c+\\sqrt{\\rho})^j-(a+c-\\sqrt{\\rho})^j)}\\\\     \\end{array} \\right. \\]"},{"location":"Composition/Rational/Particular%20case/","title":"Particular case","text":"<p>The general case only works if</p> \\[ b\\ne-\\frac{(a-c)^2}{4} \\] <p>Using this, we have</p> \\[ \\begin{pmatrix}a\\\\k\\end{pmatrix}_{j+1} =\\begin{pmatrix}a&amp;b\\\\1&amp;c\\end{pmatrix} \\begin{pmatrix}a\\\\k\\end{pmatrix}_j \\] \\[ \\begin{pmatrix}a\\\\k\\end{pmatrix}_j =\\begin{pmatrix}\\frac{a-c}{2}&amp;1\\\\1&amp;0\\end{pmatrix}\\begin{pmatrix}\\frac{a+c}{2}&amp;1\\\\0&amp;\\frac{a+c}{2}\\end{pmatrix}^j\\begin{pmatrix}0&amp;1\\\\1&amp;\\frac{c-a}{2}\\end{pmatrix}\\begin{pmatrix}1\\\\0\\end{pmatrix} \\] \\[ \\begin{pmatrix}a\\\\k\\end{pmatrix}_j =\\begin{pmatrix}j\\left(\\frac{a+c}{2}\\right)^{j-1}\\left(\\frac{a-c}{2}\\right) +\\left(\\frac{a+c}{2}\\right) \\\\ j\\left(\\frac{a+c}2\\right)^{j-1}\\end{pmatrix} \\] <p>Thus</p> \\[ \\frac{a_j}{k_j}=\\frac{a(j+1)+(1-j)c}{2j} \\] <p>Doing a similar reasonment with \\(c\\), we get</p> \\[ \\frac{c_j}{k_j}=\\frac{a(1-j)+(1+j)c}{2j} \\] <p>Thus</p> \\[ p_j(x)=\\frac{\\frac{(1+j)a+(1-j)c}{2j}x-\\left(\\frac{a-c}{2}\\right)^2}{x+\\frac{(1-j)a+(1+j)c}{2j}} \\]"},{"location":"Composition/Rational/Periodicity/","title":"Periodicity","text":"<p>For a periodic composition, we want</p> \\[ p_n(x)=x \\] <p>and thus, keeping our conventions from the general case, we want</p> \\[ \\frac{a_nx+bk_n}{k_nx+c_n}=x \\] \\[ \\left\\{     \\begin{array}{ll}       a_n=c_{n}\\\\       k_{n}=0     \\end{array} \\right. \\] <p>One can check that the second condition is sufficient for the first one to be satisfied so we will only considere this one. This second equations is equivalent to</p> \\[ \\left(a+c+\\sqrt{\\rho}\\right)^n=\\left(a+c-\\sqrt{\\rho}\\right)^n \\] <p>which is equivalent to</p> \\[ \\left(1+\\frac {\\sqrt{\\rho}} {a+c}\\right)^n=\\left(1-\\frac {\\sqrt{\\rho}}{a+c}\\right)^n \\] <p>except that it eliminates the solution \\(c=-a\\), which is a solution of period 2. To continue, we can pose \\(z=\\frac{\\rho}{(a+c)^2}\\) and apply the binomial theorem:</p> \\[ \\sum_{i=0}^j \\begin{pmatrix}j\\\\i\\end{pmatrix} z^{\\frac{i-1}{2}}=\\sum_{i=0}^j \\begin{pmatrix}j\\\\i\\end{pmatrix} (-1)^{i}z^{\\frac{i-1}{2}}. \\] <p>Let \\(i=2m+1\\) and \\(k=j-1\\), we finally have</p> \\[ \\sum_{m=0}^{\\lfloor\\frac{k}{2}\\rfloor}\\frac{k!}{(2m+1)!(k-2m)!}z^m=0. \\] <p>Finding solutions in z, we can go back to the rational function via</p> \\[ b=\\frac{(z-1)(a^2+c^2)}{4}+\\frac{(z+1)ac}{2}. \\] <p>Here is a list of solutions for z:</p> Period z 1 1 2 \\(a=-c\\) 1 3 1 -3 4 \\(a=-c\\) 1 -1 5 1 \\(\\pm2\\sqrt{5}-5\\) 6 \\(a=-c\\) 1 -3 \\(-\\frac 13\\) <p>Following solutions can be computed but they become complicated very fast. Also from a certain point, it asks to solve a polynomial of degree of 5 or more, even taking into account solutions that we get from sub-periods.</p> <p>This is, as far as I know, a complete description of the periodicity of composition of rational linear functions.</p>"}]}